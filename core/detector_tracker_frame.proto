syntax = "proto3";

package vivacity.core;
option go_package = "github.com/vivacitylabs/vivacity-proto-buffet/vivacity/core";

import "vivacity/core/point.proto";
import "vivacity/core/tracing_context.proto";
import "vivacity/core/classifying_detector_class_types.proto";
import "vivacity/core/countline_crossing.proto";
import "vivacity/core/vector.proto";
import "vivacity/core/movement.proto";
import "vivacity/core/zonal_features.proto";


message DetectionBox {  // LabelBox
    core.Point top_left = 1;  // required
    core.Point bottom_right = 2;  // required
    core.ClassifyingDetectorClassTypes detection_class = 3; // required
    float class_confidence = 4;
    string hashed_anpr_plate = 5;
    string anpr_plate = 10;
    core.Point center_center = 6;
    core.Point bottom_center = 7;
    core.Point license_plate_center_center = 8;
    repeated core.Point occupancy_zone_points = 9;
    map<string, core.Point> custom_points = 16;
    core.Point top_right = 17;
    core.Point bottom_left = 18;
    reserved 19;
    reserved 31;
}

message TrackHead {  // TrackedBox
    DetectionBox detection_box = 1; // required
    uint32 track_number = 2; // required
    bool is_predicted = 3;
    bool is_tracked = 13;
    uint64 last_detected_timestamp_microseconds = 4; // Only used when is_predicted is true
    repeated uint32 occupancy_zone_id = 5;
    repeated core.CountlineCrossing countline_crossings = 6; // optional, filled by countline_crossing
    uint64 frame_time_microseconds = 7; // optional
    reserved 8; // deprecated, use movement messages below
    bool is_stopped = 9;
    Movement movement = 10;
    core.ClassifyingDetectorClassTypes track_class = 11;
    reserved 12;
}

message DetectorTrackerFrame {
    enum VideoID {
        UNKNOWN_VIDEO_ID = 0;
        CAM0_MJPEG_YUYV = 1;
        CAM1_MJPEG_YUYV = 2;
        FILE = 3;
    }
    uint32 frame_number = 1; // This is not required unless we can't assume sequenced message transmission
    uint32 restart_number = 2; // required
    uint64 frame_time_microseconds = 3; // required
    reserved 4; // deprecated
    reserved 5; // deprecated
    uint32 vision_program_id = 6; // required
    repeated TrackHead track_heads = 7;
    core.TracingContext tracing_ctx = 8;
    repeated core.ZonalFeatures zone_oriented_features = 9;
    repeated TrackSegment track_segments = 10;
    reserved 11;
    repeated AssembledTrack track_tails = 12;
    reserved 13;
    repeated TrackHead track_terminations = 15;
}

message FragmentedDetectorTrackerFrame {
    uint32 fragment_number = 1;
    uint32 fragment_total = 2;
    uint32 total_track_heads = 3;
    DetectorTrackerFrame detector_tracker_frame_fragment = 4;
    core.TracingContext tracing_ctx = 5;
}

message AssembledTrack {
    repeated TrackHead track_heads = 1; // required
    uint32 vision_program_id = 2; // required
    core.TracingContext tracing_ctx = 3;
    uint32 restart_number = 4;  // required
    repeated uint32 turning_movement_zones = 5;
}

message AssembledTrackBatch {
    repeated AssembledTrack assembled_tracks = 1;
}

message TrackSegment {
    uint32 vision_program_id = 1; // required
    uint32 track_number = 9; // required
    TrackHead track_head_start = 2; // required
    TrackHead track_head_end = 3; // required
    TracingContext tracing_ctx = 4;
    uint32 restart_number = 5;  // required
}

message BrokenTrackStitchingMessage {
    uint32 restart_number = 1; // required
    repeated uint32 linked_track_numbers = 2; // required
    uint32 vision_program_id = 3; // required
}
